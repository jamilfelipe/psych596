---
title: "Mixed Effects activity in R, based on Brown (2021)"
author: "Lobue & Bhanji - Statistical Methods"
date: "12/6/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
knitr::opts_knit$set(root.dir = rprojroot::find_rstudio_root_file())
library(tidyverse)
library(ggplot2)
library(lme4)
```

------------------------------------------------------------------------

Today's activity is based entirely on [Violet Brown's 2021 article, "An Introduction to Linear Mixed-Effects Modeling in R." Advances in Methods and Practices in Psychological Science, 4(1), pp. 1â€“19.](https://doi.org/10.1177%2F2515245920960351)  

## Goals for today  

- Learn differences between a linear mixed effects model approach and a standard linear model approach with aggregated data for repeated measures in a crossed design  
- Learn about fixed and random effects and how to specify them in a formula using the `lme4::lmer()` function in R  
- Learn how to address problems in model fitting (failure to converge, or singular fit)  
- Learn how to interpret output from a linear mixed effects model  
- Use model comparison for significance tests of individual terms in a model  
- Learn to extend a simple two condition comparison to examine a 2x2 design, and interpret the lower order effects along with the interaction effect   

------------------------------------------------------------------------

## Step 0  

- install the required packages: 
    - `install.packages(lme4)`  
    - `afex` you should already have installed  
- setup your project folder (with data and r_docs folders within) and start a new project in this existing folder  
- start a new R markdown for your code and notes and include the usual code in the setup chunk, but add `library(lme4)` to the setup chunk (and then run the chunk)   
- Download these files and place in the data folder within your project folder:  
    - [rt_dummy_data.csv](../data/rt_dummy_data.csv) for example 1  
    - [rt_dummy_data_interaction](../data/rt_dummy_data_interaction.csv)  

    
------------------------------------------------------------------------
## Example 1: trial level analysis of a within-subject (2 level) effect  

###  Step 1 - import the first data file and check it out  
Data description:  
This data set is adapted from a study investigating comprehension of spoken words based on audio alone (Audio-only condition) vs audio with video of the speaker (Audiovisual condition). On each of 553 trials, participants heard and repeated a single word (either Audio-only or Audiovisual) while simultaneously performing a second task (judging the duration of a vibrating stimulus on their knee). The researchers hypothesized that response times for the secondary task would be longer in the Audiovisual condition than the Audio-only condition, which would indicate greater listening effort required in the Audiovisual condition. This finding is relevant to theories of speech processing.   

Variables:  
- **Dependent variable:** `RT`=response time (ms) for the secondary task  
- **Independent variable:** `modality`=listening condition ("Audio-only" or "Audiovisual")  
- `stim`=word stimulus for each trial  
- `PID`=participant identifier  

Each of 53 participants complete 553 trials. The response times have been modified as described in Brown (2012) to illustrate issues involved in linear mixed effects modeling.  

#### What to do:  
1. Use the `readr::read_csv()` function to import the `rt_dummy_data.csv` file and store it in a variable named `rt_data`. There are no missing data that you need to deal with, because trials with a missed response are not included in the data file  

2. Use the `dplyr::group_by()` and `dplyr::summarise()` functions to compute the following and print it to the screen:
    - mean RT across all trials in each modality condition  
    - median RT across all trials in each modality condition 
    - standard devation of RT across all trials in each modality condition  

3. Now, first aggregate the data by participant (calculate the number of trials each participant did of each condition, and the mean RT for each condition for each subject) and then print out:  
    - mean number of trials in each condition for a participant
    - min and max number of trials in each condition for a participant  
    - mean RT across participants (different than before bc you are first aggregating by participant)  
    - standard deviation of RT across participants  

<button class="btn btn-primary" data-toggle="collapse" data-target="#step1"> Show/Hide Solution </button>  
<div id="step1" class="collapse">  
```{r import-rt-data}
#import the data
rt_data <- readr::read_csv("data/rt_dummy_data.csv")

#descriptives across trials (ignoring participant ID)
rt_data %>% dplyr::group_by(modality) %>% dplyr::summarise(
  totalN = n(),
  trialwiseRTmean = mean(RT, na.rm = TRUE),
  trialwiseRTmedian = median(RT, na.rm = TRUE),
  trialwiseRTsd = sd(RT, na.rm = TRUE)
) %>% ungroup() %>% 
  kableExtra::kbl(caption = "descriptives by modality condition (trialwise)",
                  digits = 2) %>% 
  kableExtra::kable_classic(full_width=FALSE, lightable_options = "hover")

#calc number of trials and mean RT for each participant (by condition)
rt_bysub <- rt_data %>% dplyr::group_by(modality,PID) %>% dplyr::summarise(
  bysub_N = n(),
  bysub_RT = mean(RT)
) %>% ungroup()

# now print descriptives, calculated by first aggregating by subject
rt_bysub %>% dplyr::group_by(modality) %>% dplyr::summarise(
  bysub_mean_N = mean(bysub_N),
  bysub_min_N = min(bysub_N),
  bysub_max_N = max(bysub_N),
  bysub_mean_RT = mean(bysub_RT),
  bysub_sd_RT = sd(bysub_RT)
) %>% ungroup() %>% 
  kableExtra::kbl(caption = "descriptives, first aggregated by participant", 
                  digits = 2) %>% 
  kableExtra::kable_classic(full_width=FALSE, lightable_options = "hover")

# histogram and box plot of the trialwise data
rt_data %>% ggplot( aes(x=RT, fill=modality) ) +
  geom_histogram(position = "identity", alpha = .5, binwidth = 100) +
  theme_classic() + labs(title = "trialwise RTs - histogram")
rt_data %>% ggplot( aes(x=modality, y=RT) ) +
  geom_boxplot() + theme_classic() + labs(title = "trialwise RTs - box plot")

# histogram and box plot of the trialwise data
rt_bysub %>% ggplot( aes(x=bysub_RT, fill=modality) ) +
  geom_histogram(position = "identity", alpha = .5, binwidth = 100) +
  theme_classic() + labs(title = "RTs averaged by participant")
rt_bysub %>% ggplot( aes(x=modality, y=bysub_RT) ) +
  geom_boxplot() + theme_classic() + labs(title = "RTs averaged by participant - box plot")


```
</div>
&nbsp;

- in the trialwise data averaged by condition you should see that mean RT in the Audio-only condition is 1041 ms and in the Audiovisual condition it is 1125 ms  
- in the data that is first averaged by participant and then across participants, the mean RT in the Audio-only condition is 1044 ms and in the Audiovisual condition it is 1127 ms
- the difference in means calculated in the two different ways is due to different numbers of trials for each participant and condition in the trialwise calculation, but in the second calculation each participant's average RTs are weighted equally. The difference in the two calculations is small here but can be larger in datasets with larger imbalances.  
- You should also see that the data are positively skewed (whether we look at trialwise data or aggregated by subject) - but we have a sufficient sample size so we won't worry about it.  

------------------------------------------------------------------------

## Step 2: Use a traditional method to analyze aggregated RTs (by participant or by item)  

#### Step 2.1 - Model the data after aggregating by participant    

First, let's use each participant's average RT per condition as our unit of analysis. Once we average across trials to get a two values (Audio-only mean RT, Audio-visual mean RT) for each participant, then we can just do a paired t-test on those values like we have done before.  
Try it now, you can use the tibble of RTs averaged by subject and modality that you created in the step above (called `rt_bysub` in the solution code), and pipe it to the `t.test()` function that we've used before.    

<button class="btn btn-primary" data-toggle="collapse" data-target="#step2.1"> Show/Hide Solution </button>  
<div id="step2.1" class="collapse">  
```{r t-test}
# paired t-test with mean RT per subject in each condition
rt_bysub %>% dplyr::arrange(PID) %>% t.test(bysub_RT ~ modality, data = ., paired=TRUE)

# equivalently, you can run the same test with the lmer function. the formula will make
# more sense after doing the whole activity
rt_bysub_lmer <- rt_bysub %>% lme4::lmer(formula = bysub_RT ~ modality + 1 + (1|PID))
summary(rt_bysub_lmer)
```
</div>
&nbsp;

- The mean 
use the `lm()` function with `modality` as the predictor. Try it now - remember that `lm()` will automatically use treatment coding (dummy coding) with the first level as the reference level, so it's the same as setting "Audio-only" to 0 and "Audiovisual" to 1. Use the `summary()` function to show the model summary after you call `lm()`. 
##### 



```{r}
# first aggregate the data by modality 
rt_lm <- lm(RT ~ modality, data = rt_data)
summary(rt_lm)

rt_bysub %>% dplyr::arrange(PID) %>%
  t.test(bysub_RT ~ modality, data = ., alternative = "two.sided", paired = TRUE)

```
------------------------------------------------------------------------

## Step 3: Mixed-effects model of the effect of modality on response time  

#### Full random effect structure  
- random intercept by participant (1|PID) and stimulus (1|stim)  
- random slope of modality effect by participant (modality_dummy|PID) and by stim (modality_dummy|stim)  
From Brown (2021) p. 4: "Whereas fixed effects model average trends, random effects model the extent to which these trends vary across levels of some grouping factor (e.g., participants or items)"

```{r}
rt_data <- rt_data %>% mutate(
  modality_dummy = ifelse(modality=="Audio-only",0,1)
)
rt_full.mod <- lme4::lmer(RT ~ modality_dummy + (1 + modality_dummy|PID) + 
                      (1 + modality_dummy|stim), data = rt_data)

```

Did you get a message that the "model failed to converge"?
This model failed to converge. The first thing we'll do is try the all_fit() function from the afex package to look for an optimizer that works.
```{r}
afex::all_fit(rt_full.mod)
```

The bobyqa optimizer should work.
```{r}
rt_full.mod <- lmer(RT ~ 1 + modality + 
                      (1 + modality|PID) + (1 + modality|stim), 
                    data = rt_data, 
                    control = lmerControl(optimizer = "bobyqa"))
```

Run the all_fit() function from the afex() package for demonstration purposes
```{r}
all_fit(rt_full.mod)
```

Build a reduced model that doesn't contained the fixed effect of modality, but is otherwise identical to the full model (including the random effects structure and control parameter)
```{r}
rt_reduced.mod <- lmer(RT ~ 1 + 
                         (1 + modality|stim) + (1 + modality|PID), 
                       data = rt_data, 
                       control = lmerControl(optimizer = "bobyqa"))
```

Test for an effect of modality via a likelihood ratio test
```{r}
anova(rt_reduced.mod, rt_full.mod)
```

Use the mixed() function from the afex package for demonstration purposes (this appears in the Likelihood Ratio Tests portion of the paper)
```{r}
mixed(RT ~ 1 + modality + 
         (1 + modality|PID) + (1 + modality|stim), 
       data = rt_data, 
       control = lmerControl(optimizer = "bobyqa"), 
       method = 'LRT')
```

View summary output
```{r}
summary(rt_full.mod) 
```

The parameter estimate for the effect of condition is 83.18, which means that in this dummy data, participants are on average 83 ms slower in the audiovisual relative to the audio-only condition.

Run the coef() function to examine individual participant and item intercept and slope estimates
```{r}
coef(rt_full.mod)
```

# Testing for an interaction between modality and SNR

Load the data. Note that it's actually the same as the original data frame, but it has an extra column containing SNR. We could have been dealing with this data frame the whole time, but having an extra variable that we're not using can be confusing, so I waited to introduce it until now. 
```{r}
rt_data_interaction <- read_csv("rt_dummy_data_interaction.csv")
```

Dummy code modality and SNR so that audio-only and easy are the reference levels
```{r}
rt_data_interaction$modality <- ifelse(rt_data_interaction$modality == "Audio-only", 0, 1)
rt_data_interaction$SNR <- ifelse(rt_data_interaction$SNR == "Easy", 0, 1)
```

Build the full model, which includes all by-participant and by-item random effects except the interaction between modality and SNR, which was not included because in my experience models with random effects structures that complex will almost certainly encounter estimation issues for this kind of data and we will need to simplify the random effects structure anyway. I also want to avoid having overly complex random effects structures because this can limit power (see Matuschek et al., 2017).  

```{r}
rt_int.mod <- lmer(RT ~ 1 + modality + SNR + modality:SNR +
                     (1 + modality + SNR|stim) + (1 + modality + SNR|PID), 
                   data = rt_data_interaction)
```

This model produced a singular fit, indicating that there are some problems with estimation going on. We'll try using the all_fit() function from the afex package to see if another optimizer will work.
```{r}
all_fit(rt_int.mod)
```

All of these produced a singular fit, and the estimation issues seem to be coming from the item random effects. Given that all the optimizers produced very similar estimates for fixed and random effects, and the item random effects (particularly the slopes) are contributing very little to the total variance using all of the optimizers, we'll try removing the by-item random slopes for modality or SNR, and testing those against the full model via likelihood ratio tests to see if we can remove those (refit = FALSE because we are testing random effects, not fixed effects).
```{r}
rt_int.mod <- lmer(RT ~ 1 + modality + SNR + modality:SNR +
                     (1 + modality + SNR|stim) + (1 + modality + SNR|PID), 
                   data = rt_data_interaction)
rt_int_no_modality_stim.mod <- lmer(RT ~ 1 + modality + SNR + modality:SNR +
                     (1 + SNR|stim) + (1 + modality + SNR|PID), 
                   data = rt_data_interaction)
rt_int_no_SNR_stim.mod <- lmer(RT ~ 1 + modality + SNR + modality:SNR +
                     (1 + modality|stim) + (1 + modality + SNR|PID), 
                   data = rt_data_interaction)

anova(rt_int_no_modality_stim.mod, rt_int.mod, refit = FALSE)
anova(rt_int_no_SNR_stim.mod, rt_int.mod, refit = FALSE)
```

It looks like the model with both random slopes does not differ from either reduced model, so we'll start by removing the random slope that is contributing less to the total variance according to all previous models (the by-item random slope for SNR). 
```{r}
rt_int.mod <- lmer(RT ~ 1 + modality + SNR + modality:SNR +
                     (1 + modality|stim) + (1 + modality + SNR|PID), 
                   data = rt_data_interaction)
```

This one produced a singular fit (we already knew that would happen because we built the same model above), so let's try all_fit()
```{r}
all_fit(rt_int.mod)
```

The Nelder-Mead optimizer might work, so we'll try that one
```{r}
rt_int.mod <- lmer(RT ~ 1 + modality + SNR + modality:SNR +
                     (1 + modality|stim) + (1 + modality + SNR|PID), 
                   data = rt_data_interaction,
                   control = lmerControl(optimizer = 'Nelder_Mead'))
```

That led to convergence issues. It looks like all of these optimizers lead to estimation issues, so we'll try removing the correlation between the random intercept for stimulus and the by-stimulus random slope for modality (this is ok in this situation because we aren't actually interested in that correlation).
```{r}
rt_int.mod <- lmer(RT ~ 1 + modality + SNR + modality:SNR +
                     (0 + modality|stim) + (1|stim) + (1 + modality + SNR|PID), 
                   data = rt_data_interaction)
```

This led to a convergence warning, so we'll try all_fit() again
```{r}
all_fit(rt_int.mod)
```

The bobyqa optimizer might work, so we'll try that
```{r}
rt_int.mod <- lmer(RT ~ 1 + modality + SNR + modality:SNR +
                     (0 + modality|stim) + (1|stim) + (1 + modality + SNR|PID), 
                   data = rt_data_interaction,
                   control = lmerControl(optimizer = 'bobyqa'))
```

Looks like that converged, but let's examine the random effects output to make sure estimation went smoothly.

```{r}
summary(rt_int.mod)
```

Looks ok! We'll stick with this one.

# Testing for an effect of modality on intelligibility (binomial) 

Load data and name it acc_data
```{r}
acc_data <- read_csv("acc_dummy_data.csv")
```

Dummy code modality with audio-only as the reference level
```{r}
acc_data$modality <- ifelse(acc_data$modality == "Audio-only", 0, 1)
```

Make PID and stim factors
```{r}
acc_data$PID <- as.factor(acc_data$PID)
acc_data$stim <- as.factor(acc_data$stim)
```

Build a full model
```{r}
acc_full.mod <- glmer(acc ~ 1 + modality + 
                        (1 + modality|PID) + (1 + modality|stim), 
                      data = acc_data, 
                      family = binomial)
```

Check random effects output
```{r}
summary(acc_full.mod)
```

Build a reduced model lacking the fixed effect for modality
```{r}
acc_reduced.mod <- glmer(acc ~ 1 + 
                           (1 + modality|PID) + (1 + modality|stim), 
                         data = acc_data, 
                         family = binomial)
```

Conduct a likelihood ratio test to see if the effect of block (audio-only versus audiovisual) is significant
```{r}
anova(acc_reduced.mod, acc_full.mod)
```

# Fixed-effects only, random intercepts, and random slopes plots

Load data
```{r}
figuredata <- read_csv("figure_data.csv")
```

Make PID a factor
```{r}
figuredata$PID <- as.factor(figuredata$PID)
```

## Fixed-effects only regression plot
Build regression model and view the summary output to look at the residuals
```{r}
ols.mod <- lm(yvar ~ xvar, data = figuredata)

summary(ols.mod)
```

Build a fixed effects only plot
```{r}
ggplot(figuredata, aes(x = xvar, y = yvar)) + 
  stat_smooth(method = lm, se = FALSE, linetype = "solid", 
              color = "black", size = .6) +
  geom_point(aes(shape = PID), size = 3.25, color = "grey70") +
  scale_shape_manual(values = c(15, 16, 17, 18)) + 
  geom_segment(aes(x = xvar, xend = xvar, 
                   y = yvar, yend = fitted(ols.mod)), 
               color = "grey70") +
  scale_y_continuous(expand = c(0, 0), breaks = c(0, 750, 1500, 2250, 3000), 
                     limits = c(0, 2600)) +
  scale_x_continuous(expand = c(0, 0), breaks = c(0, 2, 4, 6, 8, 10), 
                     limits = c(-0.5, 10.5)) +
  theme(panel.background = element_blank(),         
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = "black", fill = NA),
        legend.position = "none",
        axis.text = element_text(size = 14),
        axis.title = element_text(size = 14)) +
  labs (x = "Word Difficulty", y = "Response Time") 
```

Save the figure
```{r}
ggsave("fixed_effects_plot.png", units = "in", width = 9, height = 6, dpi = 300)
```

## Random intercepts plot 

Build the model with random intercepts and view the summary output to look at the residuals
```{r}
random_intercepts.mod <- lmer(yvar ~ 1 + xvar + (1|PID), data = figuredata)

summary(random_intercepts.mod)
```

Extract the fixed effects estimates for the intercept and slope
```{r}
model_intercept <- as.numeric(fixef(random_intercepts.mod)[1])
model_slope <- as.numeric(fixef(random_intercepts.mod)[2])
```

Extract the individual participant intercepts for this model and add it to the data frame
```{r}
figuredata$intercepts <- rep(coef(random_intercepts.mod)$PID[,1], each = 4)
```

Build random intercepts plot
```{r}
ggplot(figuredata, aes(x = xvar, y = yvar)) + 
  geom_abline(slope = model_slope, intercept = model_intercept, 
              linetype = "solid", color = "black", size = 1) +
  geom_abline(mapping = aes(slope = model_slope, intercept = intercepts), 
              linetype = "dashed", color = "grey70", size = .4) + 
  geom_point(aes(shape = PID), size = 3.25, color = "grey70") + 
  scale_shape_manual(values = c(15, 16, 17, 18)) + 
  geom_segment(aes(x = xvar, xend = xvar, 
                   y = yvar, yend = fitted(random_intercepts.mod)),
               color = "grey70") +
  scale_y_continuous(expand = c(0, 0), breaks = c(0, 500, 1000, 1500, 2000, 2500), 
                     limits = c(0, 2600)) +
  scale_x_continuous(expand = c(0, 0), breaks = c(0, 2, 4, 6, 8, 10), 
                     limits = c(-0.5, 10.5)) +
  theme(panel.background = element_blank(),         
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = "black", fill = NA),
        legend.position = "none",
        axis.text = element_text(size = 14), 
        axis.title = element_text(size = 14)) +
  labs (x = "Word Difficulty", y = "Response Time") 
```

Save the figure
```{r}
ggsave("random_intercepts.png", units = "in", width = 9, height = 6, dpi = 300)
```

## Random intercepts and slopes plot

Build the model with random intercepts and slopes and view the summary output to look at the residuals
```{r}
random_slopes.mod <- lmer(yvar ~ 1 + xvar + (1 + xvar|PID), data = figuredata)

summary(random_slopes.mod)
```

Extract the individual participant intercepts and slopes from this model and add them to the data frame
```{r}
figuredata$intercepts2 <- rep(coef(random_slopes.mod)$PID[,1], each = 4)
figuredata$slopes <- rep(coef(random_slopes.mod)$PID[,2], each = 4)
```

Build plot
```{r}
ggplot(figuredata, aes(x = xvar, y = yvar)) + 
  geom_abline(slope = model_slope, intercept = model_intercept, 
              linetype = "solid", color = "black", size = 1) + 
  geom_abline(mapping = aes(slope = slopes, 
                            intercept = intercepts2, linetype = PID), 
              linetype = "dashed", color = "grey70", size = .4) +
  geom_point(aes(shape = PID), size = 3.25, color = "grey70") + 
  scale_shape_manual(values = c(15, 16, 17, 18)) + 
  geom_segment(aes(x = xvar, xend = xvar, 
                   y = yvar, yend = fitted(random_slopes.mod)), 
               color = "grey70") +
  scale_y_continuous(expand = c(0, 0), breaks = c(0, 750, 1500, 2250), 
                     limits = c(0, 2600)) +
  scale_x_continuous(expand = c(0, 0), breaks = c(0, 2, 4, 6, 8, 10), 
                     limits = c(-0.5, 10.5)) +
  theme(panel.background = element_blank(),         
        panel.grid.major = element_blank(),
        panel.grid.minor = element_blank(),
        panel.border = element_rect(colour = "black", fill = NA),
        legend.position = "none", 
        axis.text = element_text(size = 14),
        axis.title = element_text(size = 14)) +
  labs (x = "Word Difficulty", y = "Response Time") 
```

Save the figure
```{r}
ggsave("random_slopes.png", units = "in", width = 9, height = 6, dpi = 300)
```

